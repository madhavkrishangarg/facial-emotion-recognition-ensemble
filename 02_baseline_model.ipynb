{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42761e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58320fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a872fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_val = (\"data_folder\\\\images\\\\images\\\\train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082761f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = os.listdir(\"data_folder\\\\images\\\\images\\\\train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c645979",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8fbcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will be building an extra set of images for running all our algorithms in order to train all our models\n",
    "#This is just to speed up the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cc11fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_images = 10000\n",
    "\n",
    "for i in emotions:\n",
    "    size_folder = len(os.listdir(os.path.join(path_val, i)))\n",
    "    min_images = min(min_images, size_folder)\n",
    "    print(i, size_folder)\n",
    "\n",
    "print(min_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16062e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##For just verification\n",
    "os.listdir(os.path.join(path_val, 'angry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9069fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's bulid a 2 dimensional array containing all the names of the images for each of the emotions\n",
    "images = [[]]*len(emotions)\n",
    "\n",
    "for i in range(len(emotions)):\n",
    "    images[i] = os.listdir(os.path.join(path_val, emotions[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d27806",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(Image.open(os.path.join(path_val, emotions[0], images[0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f73a57d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Debugging\n",
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24781be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "angry = []\n",
    "disgust = []\n",
    "fear = []\n",
    "happy = []\n",
    "neutral = []\n",
    "sad = []\n",
    "surprise = []\n",
    "for i in tqdm(range(len(images[0]))):\n",
    "    angry += [np.array(Image.open(os.path.join(path_val, emotions[0], images[0][i])))]\n",
    "\n",
    "for i in tqdm(range(len(images[1]))):\n",
    "    disgust += [np.array(Image.open(os.path.join(path_val, emotions[1], images[1][i])))]\n",
    "\n",
    "for i in tqdm(range(len(images[2]))):\n",
    "    fear += [np.array(Image.open(os.path.join(path_val, emotions[2], images[2][i])))]\n",
    "\n",
    "for i in tqdm(range(len(images[3]))):\n",
    "    happy += [np.array(Image.open(os.path.join(path_val, emotions[3], images[3][i])))]\n",
    "\n",
    "for i in tqdm(range(len(images[4]))):\n",
    "    neutral += [np.array(Image.open(os.path.join(path_val, emotions[4], images[4][i])))]\n",
    "\n",
    "for i in tqdm(range(len(images[5]))):\n",
    "    sad += [np.array(Image.open(os.path.join(path_val, emotions[5], images[5][i])))]\n",
    "\n",
    "for i in tqdm(range(len(images[6]))):\n",
    "    surprise += [np.array(Image.open(os.path.join(path_val, emotions[6], images[6][i])))]\n",
    "\n",
    "images_array = [angry, disgust, fear, happy, neutral, sad, surprise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09942661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building numpy arrays for training and testing from the orifinal values\n",
    "from tqdm import notebook\n",
    "\n",
    "y = []\n",
    "x = []\n",
    "for i in notebook.tqdm(range(len(images_array))):\n",
    "    for j in notebook.tqdm(range(len(images_array[i]))):\n",
    "        y += [i]\n",
    "        x += [images_array[i][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef29b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "x = np.array(x)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25f90a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#For validation set and training set\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a5094",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding our values\n",
    "import tensorflow as tf\n",
    "print(np.unique(y_train))\n",
    "Y_train_onehot = np.array(tf.keras.utils.to_categorical(y_train, num_classes = 7))\n",
    "Y_val_onehot = np.array(tf.keras.utils.to_categorical(y_val, num_classes = 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb8072",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(angry).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_ = os.listdir(os.path.join(path_val, emotions[len(emotions) - 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24978b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(Image.open(os.path.join(path_val, emotions[len(emotions) - 1], last_[len(last_) - 1]))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dad9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "compact_training_data = np.array([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950f941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have multiple ideas, so working on them in the follwoing cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d685992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import  Activation, Dense, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c296db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Conv2D(32, kernel_size = (3, 3), activation = 'relu', input_shape = (48, 48, 1)))\n",
    "model1.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model1.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "model1.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu'))\n",
    "model1.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model1.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu'))\n",
    "model1.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(1024, activation = 'relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(7, activation = 'softmax'))\n",
    "\n",
    "model1.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fcee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model1.fit(x_train/255., Y_train_onehot, epochs = 8, validation_data = (x_val/255., Y_val_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c709430",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = model1.predict(x_val/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f2c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_pred_val[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3180c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as im\n",
    "\n",
    "print(y_val[0])\n",
    "print(y_pred_val[0])\n",
    "im.fromarray(x_val[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1dc6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vals = []\n",
    "for i in range(len(y_pred_val)):\n",
    "    max_vals += [np.max(y_pred_val[i])]\n",
    "\n",
    "max_vals = np.array(max_vals)\n",
    "#print(max_vals)\n",
    "print(np.count_nonzero(max_vals < 0.5))\n",
    "print(len(max_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6ac87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_clear_vals = np.where(max_vals < 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e27406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unclear_category = []\n",
    "for i in not_clear_vals:\n",
    "    unclear_category += [y_val[i]]\n",
    "\n",
    "unclear_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af40928",
   "metadata": {},
   "outputs": [],
   "source": [
    "unclear_category[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e4358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = [0] * 7\n",
    "for i in unclear_category[0]:\n",
    "    freq[i] = freq[i] + 1\n",
    "\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed2e0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(max_vals < 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab157760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam,SGD,RMSprop\n",
    "from tensorflow import keras\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#1st CNN layer\n",
    "model.add(Conv2D(64,(3,3),padding = 'same', activation = 'relu', input_shape = (48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#2nd CNN layer\n",
    "model.add(Conv2D(128,(3,3), activation = 'relu',padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout (0.25))\n",
    "\n",
    "#3rd CNN layer\n",
    "model.add(Conv2D(128,(3,3), activation = 'relu',padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout (0.25))\n",
    "\n",
    "#4th CNN layer\n",
    "model.add(Conv2D(256,(3,3), activation = 'relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#Fully connected 1st layer\n",
    "model.add(Dense(1024))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# Fully connected layer 2nd layer\n",
    "# model.add(Dense(512))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(no_of_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "# opt = Adam(lr = 0.0001)\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum = 0.5)  # replace \"lr\" with \"learning_rate\"\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6bb309",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model.fit(x_train/255., Y_train_onehot, epochs = 8, validation_data = (x_val/255., Y_val_onehot))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
